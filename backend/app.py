#backend
from flask import Flask, jsonify
from flask_cors import CORS
import pandas as pd

app = Flask(__name__)
CORS(app)


import random

import os

base_dir = os.path.dirname(__file__)
file_path = os.path.join(base_dir, "data", "DATA - AI-Powered Bundling & Pricing Strategist.xlsx")


#file_path = r"C:\Users\Lampr\OneDrive - unipi.gr\Desktop\DataCleansing\DATA - AI-Powered Bundling & Pricing Strategist.xlsx"

#Load data
import numpy as np


# Load both sheets
orders_df = pd.read_excel(file_path, sheet_name='orders')
inventory_df = pd.read_excel(file_path, sheet_name='inventory')

# === 1. Clean Orders Data ===
orders_df.drop_duplicates(inplace=True)

# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Quantity ÏƒÎµ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÏŒ ÎºÎ±Î¹ Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î¸ÎµÏ„Î¹ÎºÏÎ½ Ï„Î¹Î¼ÏÎ½
orders_df['Quantity'] = pd.to_numeric(orders_df['Quantity'], errors='coerce')
orders_df = orders_df[orders_df['Quantity'] > 0]

# Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Î³ÏÎ±Î¼Î¼ÏÎ½ Î¼Îµ ÎºÏÎ¯ÏƒÎ¹Î¼Î± missing values
orders_df.dropna(subset=['OrderNumber', 'SKU', 'Item title', 'Quantity'], inplace=True)

# ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½ ÏƒÏ„Î·Î»ÏÎ½ (Î±Ï†Î±Î¯ÏÎµÏƒÎ· ÎºÎµÎ½ÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÏ‰Î½)
orders_df.columns = [col.strip() for col in orders_df.columns]
inventory_df.columns = [col.strip() for col in inventory_df.columns]

# === 1.1 Remove gifts and zero-price products ===
# Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Ï€Î¹Î¸Î±Î½ÏÏ‚ promotional (Î´Ï‰ÏÎµÎ¬Î½, Î´ÎµÎ¯Î³Î¼Î±Ï„Î±)
gift_keywords = ['gift', 'Î´ÏÏÎ¿', 'sample', 'miniature']
pattern = '|'.join(gift_keywords)

orders_df = orders_df[~orders_df['Item title'].str.lower().str.contains(pattern)]
orders_df = orders_df[orders_df['FinalUnitPrice'] > 0]

# === 2. Clean Inventory Data ===
inventory_df = inventory_df.dropna(subset=['SKU', 'Quantity'])
inventory_df = inventory_df[inventory_df['Quantity'] > 0]
inventory_df.to_csv("data/inventory.csv", index=False)

# ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ SKU Î³Î¹Î± Î¼ÎµÏ„Î±Î³ÎµÎ½Î­ÏƒÏ„ÎµÏÎ· Ï‡ÏÎ®ÏƒÎ·
valid_skus = inventory_df['SKU'].unique()
available_skus_set = set(valid_skus)

# === 3. Merge Orders with Inventory Info ===
orders_df = orders_df.merge(inventory_df, on="SKU", how="left")
orders_df.rename(columns={'Quantity_x': 'OrderQuantity', 'Quantity_y': 'InventoryQuantity'}, inplace=True)
orders_df['InventoryQuantity'] = orders_df['InventoryQuantity'].fillna(0)
orders_df['SKU_in_stock'] = orders_df['InventoryQuantity'] > 0

# === 4. Filter Only SKUs with Enough Frequency for Modeling ===
# Î™ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± Î±Î½Î¬Î¼ÎµÏƒÎ± ÏƒÎµ ÎºÎ¬Î»Ï…ÏˆÎ· ÎºÎ±Î¹ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±
min_order_count = 1
sku_order_counts = orders_df.groupby('SKU')['OrderNumber'].nunique()
frequent_skus = sku_order_counts[sku_order_counts >= min_order_count].index
orders_df = orders_df[orders_df['SKU'].isin(frequent_skus)]

# === 5. Optional Sampling for Basket Algorithms ===
sample_size = 130000  # Î³Î¹Î± FP-Growth Î® Apriori
unique_orders = orders_df['OrderNumber'].drop_duplicates()
if len(unique_orders) > sample_size:
    sampled_orders = unique_orders.sample(sample_size, random_state=42)
    orders_df = orders_df[orders_df['OrderNumber'].isin(sampled_orders)]

# === 6. Final Info ===
print(f"ğŸ§¾ Orders after cleaning: {orders_df.shape[0]}")
print(f"âœ… Unique Orders: {orders_df['OrderNumber'].nunique()}")
print(f"ğŸ“¦ SKUs in stock: {orders_df['SKU_in_stock'].sum()}")
print(f"âš ï¸ SKUs out of stock: {(~orders_df['SKU_in_stock']).sum()}")

orders_df['ProductID'] = orders_df['SKU'].astype(str) + ' - ' + orders_df['Item title']

# === 6.1 Create unique ProductID ===
# Î£Ï…Î½Î´Ï…Î¬Î¶ÎµÎ¹ SKU + Item title Î³Î¹Î± Î½Î± Î¾ÎµÏ‡Ï‰ÏÎ¯Î¶ÎµÎ¹Ï‚ Ï€Î±ÏÎ±Î»Î»Î±Î³Î­Ï‚


# === 7. Rule-Based Bundle Generation (Top-Sellers + Same Brand) ===

# Î’ÏÎµÏ‚ Ï„Î± Top 50 Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ ÏƒÏ…Î½Î¿Î»Î¹ÎºÏŒ OrderQuantity
top_products = (
    orders_df.groupby('ProductID')['OrderQuantity'].sum()
    .sort_values(ascending=False)
    .head(50)
    .index
)

# Î Î¯Î½Î±ÎºÎ±Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ (Ï‡Ï‰ÏÎ¯Ï‚ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±)
product_info = orders_df.drop_duplicates(subset='ProductID')[
    ['ProductID', 'Brand', 'Category', 'SKU', 'Item title']
].set_index('ProductID')

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± candidate bundles Î¼Îµ Î²Î¬ÏƒÎ· Î¯Î´Î¹Î¿ Brand
bundle_candidates = []

for prod_id in top_products:
    brand = product_info.loc[prod_id, 'Brand']

    # Î’ÏÎµÏ‚ Î­Ï‰Ï‚ 3 ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î± Ï„Î¿Ï… Î¯Î´Î¹Î¿Ï… brand (ÎµÎºÏ„ÏŒÏ‚ Ï„Î¿Ï… Î¯Î´Î¹Î¿Ï… Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚)
    related_products = product_info[
        (product_info['Brand'] == brand) &
        (product_info.index != prod_id)
    ].index[:3]

    for related_id in related_products:
        bundle_candidates.append((prod_id, related_id))
# === Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ===
print(f"\nğŸ“¦ Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ {len(bundle_candidates)} candidate bundles.")
print("ğŸ§  Rule-based Bundles (Top-sellers + Same Brand):")
for a, b in bundle_candidates[:10]:
    title_a = product_info.loc[a, 'Item title']
    title_b = product_info.loc[b, 'Item title']
    print(f"ğŸ‘‰ {title_a} + {title_b}")


# ğŸ”„ Convert tuple list to DataFrame and enrich with titles
bundle_rows = []

for a, b in bundle_candidates:
    bundle_rows.append({
        "Primary Product ID": a,
        "Primary Title": product_info.loc[a, 'Item title'],
        "Bundled With Product ID": b,
        "Bundled With Title": product_info.loc[b, 'Item title'],
        "Brand": product_info.loc[a, 'Brand']
    })

# ğŸ“¤ Convert to DataFrame
top_seller_bundles_df = pd.DataFrame(bundle_rows)

# ğŸ’¾ Save as CSV for chatbot input
top_seller_bundles_df.to_csv("top_seller_bundles.csv", index=False)
print("âœ… Exported bundle suggestions to 'top_seller_bundles.csv'")

# === Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataFrame Î±Ï€ÏŒ Ï„Î± Ï…Ï€Î¬ÏÏ‡Î¿Î½Ï„Î± bundle_candidates ===
rule_bundles_df = pd.DataFrame(bundle_candidates, columns=['ProductID_A', 'ProductID_B'])

# Î Î¯Î½Î±ÎºÎ±Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½
product_info = orders_df.drop_duplicates(subset='ProductID')[
    ['ProductID', 'Brand', 'Category', 'SKU', 'Item title']
].set_index('ProductID')

# Merge Î³Î¹Î± Î½Î± Ï†Î­ÏÎ¿Ï…Î¼Îµ Ï„Î¯Ï„Î»Î¿Ï…Ï‚ ÎºÎ±Î¹ SKUs
rule_bundles_df = rule_bundles_df.merge(product_info, left_on='ProductID_A', right_index=True)
rule_bundles_df = rule_bundles_df.merge(product_info, left_on='ProductID_B', right_index=True, suffixes=('_A', '_B'))

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± bundle Ï„Î¯Ï„Î»Î¿Ï… ÎºÎ±Î¹ Ï„ÏÏ€Î¿Ï…
rule_bundles_df['Suggested Bundle Title'] = rule_bundles_df['Item title_A'] + " + " + rule_bundles_df['Item title_B']
rule_bundles_df['BundleType'] = 'Rule-Based'

# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚
print(f"\nğŸ“¦ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ rule_bundles_df Î¼Îµ {len(rule_bundles_df)} Î³ÏÎ±Î¼Î¼Î­Ï‚.")
print(rule_bundles_df.head())

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import itertools

# === 1. Î Î¬ÏÎµ Î¼Î¿Î½Î±Î´Î¹ÎºÎ¿ÏÏ‚ Ï„Î¯Ï„Î»Î¿Ï…Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ ===
product_titles = orders_df[['ProductID', 'Item title']].drop_duplicates().reset_index(drop=True)

# === 2. TF-IDF Vectorization ===
vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)
tfidf_matrix = vectorizer.fit_transform(product_titles['Item title'])

# === 3. KMeans Clustering ===
num_clusters = 5
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')
product_titles['Cluster'] = kmeans.fit_predict(tfidf_matrix)

# === 4. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î¸ÎµÎ¼Î±Ï„Î¹ÎºÏÎ½ bundles Î±Ï€ÏŒ ÎºÎ¬Î¸Îµ cluster ===
cluster_bundles = []

for cluster_id in range(num_clusters):
    cluster_items = product_titles[product_titles['Cluster'] == cluster_id]['Item title'].tolist()

    # Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼Î¿Î¯ 2 Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Î±Î½Î¬ cluster
    combos = list(itertools.combinations(cluster_items[:10], 2))  # Ï€ÎµÏÎ¹Î¿ÏÎ¯Î¶Î¿Ï…Î¼Îµ ÏƒÏ„Î± 10 Î³Î¹Î± Î»Î¿Î³Î¹ÎºÏŒ ÏŒÎ³ÎºÎ¿
    cluster_bundles.extend(combos)

# === 5. Î ÏÎ¿Î²Î¿Î»Î® ===
print(f"ğŸ§  Thematic Bundles via TF-IDF + KMeans (Clusters: {num_clusters})")
print(f"ğŸ“¦ Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ {len(cluster_bundles)} thematic bundles.\n")

# Î”ÎµÎ¯Î¾Îµ Ï„Î± Ï€ÏÏÏ„Î± 10
for a, b in cluster_bundles[:10]:
    print(f"ğŸ‘‰ {a} + {b}")

# === 6. ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ DataFrame ÎºÎ±Î¹ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ===
thematic_bundle_df = pd.DataFrame(cluster_bundles, columns=['Product A', 'Product B'])

# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Cluster ID Î³Î¹Î± ÎµÏ€Î¹Ï€Î»Î­Î¿Î½ Ï€Î»Î·ÏÎ¿Ï†ÏŒÏÎ·ÏƒÎ· (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ)
thematic_bundle_df['Cluster'] = None
for cluster_id in range(num_clusters):
    items = product_titles[product_titles['Cluster'] == cluster_id]['Item title'].tolist()
    cluster_combos = list(itertools.combinations(items[:10], 2))
    for combo in cluster_combos:
        thematic_bundle_df.loc[
            (thematic_bundle_df['Product A'] == combo[0]) &
            (thematic_bundle_df['Product B'] == combo[1]), 'Cluster'
        ] = cluster_id

# === Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÎµ CSV ===
thematic_bundle_df.to_csv("thematic_bundles.csv", index=False)
print("âœ… Exported thematic bundles to 'thematic_bundles.csv'")

# === Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataFrame Î±Ï€ÏŒ Ï„Î± cluster_bundles ===
thematic_bundles_df = pd.DataFrame(cluster_bundles, columns=['Item title A', 'Item title B'])

# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î¯Ï„Î»Î¿Ï… ÎºÎ±Î¹ Ï„ÏÏ€Î¿Ï… bundle
thematic_bundles_df['Suggested Bundle Title'] = thematic_bundles_df['Item title A'] + " + " + thematic_bundles_df['Item title B']
thematic_bundles_df['BundleType'] = 'Thematic'

# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚
print(f"\nğŸ“¦ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ thematic_bundles_df Î¼Îµ {len(thematic_bundles_df)} Î³ÏÎ±Î¼Î¼Î­Ï‚.")
print(thematic_bundles_df.head())

# === 4.1 Volume Bundles â€“ Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Ï€Î¿Ï… Î±Î³Î¿ÏÎ¬Î¶Î¿Î½Ï„Î±Î¹ ÏƒÎµ Ï€Î¿ÏƒÏŒÏ„Î·Ï„ÎµÏ‚ ===

# ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Î½Î¬ Ï€ÏÎ¿ÏŠÏŒÎ½: Ï€ÏŒÏƒÎµÏ‚ Ï€Î±ÏÎ±Î³Î³ÎµÎ»Î¯ÎµÏ‚, Î¼Î­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚, Î¼Î­Î³Î¹ÏƒÏ„Î· Ï€Î¿ÏƒÏŒÏ„Î·Ï„Î±
volume_df = orders_df.groupby(['SKU', 'Item title'])['OrderQuantity'].agg(['count', 'mean', 'max']).reset_index()
volume_df.columns = ['SKU', 'Item title', 'Order Count', 'Avg Quantity', 'Max Quantity']

# Î•Ï€Î¹Î»Î¿Î³Î® Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½ Î³Î¹Î± volume bundles
volume_bundles = volume_df[(volume_df['Avg Quantity'] >= 2) | (volume_df['Max Quantity'] >= 3)].copy()

# === ÎˆÎ¾Ï…Ï€Î½Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î¼Î­Î³ÎµÎ¸Î¿Ï‚ bundle Î¼Îµ upper limit ===
def smart_bundle_qty(avg_qty, max_qty=4):
    if avg_qty < 1.8:
        return 2
    elif avg_qty < 2.5:
        return 3
    elif avg_qty < 3.5:
        return 4
    else:
        return min(round(avg_qty), max_qty)

# === Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î¯Ï„Î»Î¿Ï… Ï€ÏÎ¿ÏƒÏ†Î¿ÏÎ¬Ï‚ Ï‡Ï‰ÏÎ¯Ï‚ Ï„Î¹Î¼Î® ===
def create_bundle_title(row):
    qty = smart_bundle_qty(row['Avg Quantity'])
    return f"{qty}x {row['Item title']} â€“ Offer Pack"

volume_bundles['Suggested Bundle Title'] = volume_bundles.apply(create_bundle_title, axis=1)

# === Î ÏÎ¿Î²Î¿Î»Î® Ï„Ï‰Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ===
print(f"ğŸ“¦ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ {len(volume_bundles)} Volume Bundles Î¼Îµ Ï€ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿Ï…Ï‚ Ï„Î¯Ï„Î»Î¿Ï…Ï‚:\n")
for i, row in volume_bundles.head(10).iterrows():
    print(f"ğŸ‘‰ {row['Suggested Bundle Title']} (Avg: {row['Avg Quantity']:.1f})")

# === Export Volume Bundles to CSV for chatbot ===
volume_bundles_export = volume_bundles[[
    'SKU', 'Item title', 'Order Count', 'Avg Quantity', 'Max Quantity', 'Suggested Bundle Title'
]]

volume_bundles_export.to_csv("volume_bundles.csv", index=False)
print("âœ… Exported volume-based bundles to 'volume_bundles.csv'")

# === ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® volume_bundles ÏƒÎµ Ï€Î»Î®ÏÎµÏ‚ DataFrame Î³Î¹Î± unified pricing ===

# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï€Î¿ÏƒÏŒÏ„Î·Ï„Î±Ï‚ bundle (Qty)
volume_bundles['Qty'] = volume_bundles['Avg Quantity'].apply(smart_bundle_qty)

# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„ÏÏ€Î¿Ï… bundle
volume_bundles['BundleType'] = 'Volume'

# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚
print(f"\nğŸ“¦ volume_bundles now ready for pricing with {len(volume_bundles)} bundles.")
print(volume_bundles[['SKU', 'Item title', 'Qty', 'Suggested Bundle Title', 'BundleType']].head())

# === 6.2 Î Î¯Î½Î±ÎºÎ±Ï‚ Î¼Îµ Î²Î±ÏƒÎ¹ÎºÎ­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Î½Î¬ Ï€ÏÎ¿ÏŠÏŒÎ½ ===
product_info = orders_df.drop_duplicates(subset='ProductID')[
    ['ProductID', 'Brand', 'Category', 'SKU', 'Item title']
].merge(inventory_df[['SKU', 'Quantity']], on='SKU', how='left')

# === 6.3 Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï€Ï‰Î»Î®ÏƒÎµÏ‰Î½ Î±Î½Î¬ ProductID ===
product_sales = orders_df.groupby('ProductID')['OrderNumber'].nunique().reset_index()
product_sales.columns = ['ProductID', 'OrderCount']

# === 6.4 Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± clearance Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ ===
min_stock = 10
clearance_products = product_sales[
    product_sales['OrderCount'] <= 3
].merge(product_info, on='ProductID')
clearance_products = clearance_products[clearance_products['Quantity'] >= min_stock]

# === 6.5 Î•Ï€Î¹Î»Î¿Î³Î® Top 50 bestsellers ===
top_products = (
    orders_df.groupby('ProductID')['OrderQuantity'].sum()
    .sort_values(ascending=False)
    .head(50)
    .index
)

# === 6.6 Î•Ï€Î±Î½Î±Ï†Î¿ÏÎ¬ product_info Î³Î¹Î± ÎµÏÎºÎ¿Î»Î· Ï‡ÏÎ®ÏƒÎ· Î¼Îµ index ===
product_info = product_info.set_index('ProductID')

# === 6.7 Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± bundles: Top-seller + Clearance (Same Brand) ===
bundle_candidates = []

for prod_id in top_products:
    if prod_id not in product_info.index:
        continue  # Skip if missing data
    brand = product_info.loc[prod_id, 'Brand']

    # Clearance Ï„Î¿Ï… Î¯Î´Î¹Î¿Ï… brand (ÏŒÏ‡Î¹ Ï„Î¿ Î¯Î´Î¹Î¿ Ï€ÏÎ¿ÏŠÏŒÎ½)
    related_clearance = clearance_products[
        (clearance_products['Brand'] == brand) &
        (clearance_products['ProductID'] != prod_id)
    ]

    for _, row in related_clearance.head(3).iterrows():  # Î­Ï‰Ï‚ 3 Î±Î½Î¬ bestseller
        bundle_candidates.append((prod_id, row['ProductID']))

# === 6.8 Î ÏÎ¿Î²Î¿Î»Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ===
print(f"\nğŸ“¦ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ {len(bundle_candidates)} Clearance Bundles (Top-seller + Same Brand with stock â‰¥ {min_stock}).")
print("ğŸ§  Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î± Bundles:")
for a, b in bundle_candidates[:10]:
    title_a = product_info.loc[a, 'Item title']
    title_b = product_info.loc[b, 'Item title']
    print(f"ğŸ‘‰ {title_a} + {title_b} (Clearance)")

# === 6.9 ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ DataFrame ÎºÎ±Î¹ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ===
clearance_bundle_rows = []

for a, b in bundle_candidates:
    clearance_bundle_rows.append({
        "Top Seller ID": a,
        "Top Seller Title": product_info.loc[a, 'Item title'],
        "Clearance Product ID": b,
        "Clearance Title": product_info.loc[b, 'Item title'],
        "Brand": product_info.loc[a, 'Brand']
    })

# Convert to DataFrame
clearance_bundle_df = pd.DataFrame(clearance_bundle_rows)

# Save to CSV
clearance_bundle_df.to_csv("clearance_bundles.csv", index=False)
print("âœ… Exported clearance bundles to 'clearance_bundles.csv'")

# === Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataFrame Î³Î¹Î± Clearance Bundles ===
clearance_bundles_df = pd.DataFrame(bundle_candidates, columns=['ProductID_A', 'ProductID_B'])

# Î•Ï€Î±Î½Î±Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… product_info Î³Î¹Î± Ï„Î¯Ï„Î»Î¿Ï…Ï‚, SKU, brand
# (Î­Ï‡ÎµÎ¹ Î®Î´Î· Î³Î¯Î½ÎµÎ¹ set_index ÏƒÏ„Î¿ ProductID)

# Merge Î³Î¹Î± Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï„Ï‰Î½ Î´ÏÎ¿ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½
clearance_bundles_df = clearance_bundles_df.merge(product_info, left_on='ProductID_A', right_index=True)
clearance_bundles_df = clearance_bundles_df.merge(product_info, left_on='ProductID_B', right_index=True, suffixes=('_A', '_B'))

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î¯Ï„Î»Î¿Ï… bundle ÎºÎ±Î¹ Ï„ÏÏ€Î¿Ï…
clearance_bundles_df['Suggested Bundle Title'] = clearance_bundles_df['Item title_A'] + " + " + clearance_bundles_df['Item title_B']
clearance_bundles_df['BundleType'] = 'Clearance'

# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚
print(f"\nğŸ“¦ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ clearance_bundles_df Î¼Îµ {len(clearance_bundles_df)} Î³ÏÎ±Î¼Î¼Î­Ï‚.")
print(clearance_bundles_df.head())



# === 1. Î•Ï„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Ï€Î·Î³ÏÎ½ Ï„Î¹Î¼Î®Ï‚ ===
avg_prices = orders_df.groupby('SKU')['FinalUnitPrice'].mean().reset_index()
avg_prices.columns = ['SKU', 'UnitPrice']

# === 2. Volume Pricing ===
volume_pricing = volume_bundles[['SKU', 'Item title', 'Qty', 'Suggested Bundle Title']].copy()
volume_pricing = volume_pricing.merge(avg_prices, on='SKU', how='left')
volume_pricing['FullPrice'] = volume_pricing['Qty'] * volume_pricing['UnitPrice']
# Dynamic discount: more units = more discount, but max at 25%
volume_pricing['DiscountRate'] = volume_pricing['Qty'].apply(
    lambda q: min(0.05 + 0.05 * (q - 2), 0.25)
)

volume_pricing['FinalPrice'] = volume_pricing['FullPrice'] * (1 - volume_pricing['DiscountRate'])
volume_pricing['BundleType'] = 'Volume'

# === 3. Rule-Based Pricing ===
rule_pricing = rule_bundles_df[['SKU_A', 'SKU_B', 'Suggested Bundle Title']].copy()
rule_pricing = rule_pricing.merge(avg_prices, left_on='SKU_A', right_on='SKU', how='left').rename(columns={'UnitPrice': 'Price_A'}).drop('SKU', axis=1)
rule_pricing = rule_pricing.merge(avg_prices, left_on='SKU_B', right_on='SKU', how='left').rename(columns={'UnitPrice': 'Price_B'}).drop('SKU', axis=1)
rule_pricing['FullPrice'] = rule_pricing['Price_A'] + rule_pricing['Price_B']
# Dynamic discount based on number of combined orders of A + B
sku_pair_counts = orders_df.groupby(['OrderNumber'])['SKU'].apply(list)
def pair_order_count(row):
    return sum((row['SKU_A'] in s and row['SKU_B'] in s) for s in sku_pair_counts)

rule_pricing['PairOrderCount'] = rule_pricing.apply(pair_order_count, axis=1)
# Î‘Î½ Ï„Î¿ Î¶ÎµÏÎ³Î¿Ï‚ Î±Î³Î¿ÏÎ¬Î¶ÎµÏ„Î±Î¹ ÏƒÏ€Î¬Î½Î¹Î± â†’ Î´ÏÏƒÎµ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ· Î­ÎºÏ€Ï„Ï‰ÏƒÎ· Î³Î¹Î± Î½Î± Ï„Î¿ Ï€ÏÎ¿Ï‰Î¸Î®ÏƒÎµÎ¹Ï‚
rule_pricing['DiscountRate'] = rule_pricing['PairOrderCount'].apply(
    lambda c: 0.20 if c < 10 else 0.10 if c < 50 else 0.05
)


rule_pricing['FinalPrice'] = rule_pricing['FullPrice'] * (1 - rule_pricing['DiscountRate'])
rule_pricing['BundleType'] = 'Rule-Based'

# === 4. Clearance Pricing ===
clearance_pricing = clearance_bundles_df[['SKU_A', 'SKU_B', 'Suggested Bundle Title']].copy()
clearance_pricing = clearance_pricing.merge(avg_prices, left_on='SKU_A', right_on='SKU', how='left').rename(columns={'UnitPrice': 'Price_A'}).drop('SKU', axis=1)
clearance_pricing = clearance_pricing.merge(avg_prices, left_on='SKU_B', right_on='SKU', how='left').rename(columns={'UnitPrice': 'Price_B'}).drop('SKU', axis=1)
clearance_pricing['FullPrice'] = clearance_pricing['Price_A'] + clearance_pricing['Price_B']
# Dynamic discount based on inventory levels â€” higher stock = higher clearance discount
inventory_map = inventory_df.set_index('SKU')['Quantity'].to_dict()

def clearance_discount(row):
    stock_a = inventory_map.get(row['SKU_A'], 0)
    stock_b = inventory_map.get(row['SKU_B'], 0)
    total_stock = stock_a + stock_b
    return 0.15 if total_stock < 20 else 0.25 if total_stock < 50 else 0.35

clearance_pricing['DiscountRate'] = clearance_pricing.apply(clearance_discount, axis=1)

clearance_pricing['FinalPrice'] = clearance_pricing['FullPrice'] * (1 - clearance_pricing['DiscountRate'])
clearance_pricing['BundleType'] = 'Clearance'

# === 5. Thematic Pricing ===
thematic_pricing = thematic_bundles_df[['Item title A', 'Item title B', 'Suggested Bundle Title']].copy()

# Î“Î¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï„Î¹Î¼Î­Ï‚, ÎºÎ¬Î½Î¿Ï…Î¼Îµ match Î¼Îµ orders_df
item_price_map = orders_df.groupby('Item title')['FinalUnitPrice'].mean().to_dict()
thematic_pricing['Price_A'] = thematic_pricing['Item title A'].map(item_price_map)
thematic_pricing['Price_B'] = thematic_pricing['Item title B'].map(item_price_map)
thematic_pricing['FullPrice'] = thematic_pricing['Price_A'] + thematic_pricing['Price_B']
# Dynamic discount based on average price: more expensive bundles = better discount
thematic_pricing['AvgItemPrice'] = (thematic_pricing['Price_A'] + thematic_pricing['Price_B']) / 2
thematic_pricing['DiscountRate'] = thematic_pricing['AvgItemPrice'].apply(
    lambda p: 0.05 if p < 10 else 0.10 if p < 25 else 0.15
)

thematic_pricing['FinalPrice'] = thematic_pricing['FullPrice'] * (1 - thematic_pricing['DiscountRate'])
thematic_pricing['BundleType'] = 'Thematic'

# === 6. Î•Î½Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ bundles ===
all_bundles = pd.concat([
    volume_pricing[['Suggested Bundle Title', 'FullPrice', 'DiscountRate', 'FinalPrice', 'BundleType']],
    rule_pricing[['Suggested Bundle Title', 'FullPrice', 'DiscountRate', 'FinalPrice', 'BundleType']],
    clearance_pricing[['Suggested Bundle Title', 'FullPrice', 'DiscountRate', 'FinalPrice', 'BundleType']],
    thematic_pricing[['Suggested Bundle Title', 'FullPrice', 'DiscountRate', 'FinalPrice', 'BundleType']]
], ignore_index=True)

# Formatting
all_bundles['FinalPrice'] = all_bundles['FinalPrice'].round(2)
all_bundles['OfferLabel'] = all_bundles['DiscountRate'].apply(lambda x: f"-{int(x*100)}%")
all_bundles = all_bundles.sort_values(by='FinalPrice')

# === 7. Î ÏÎ¿Î²Î¿Î»Î® Ï„ÎµÎ»Î¹ÎºÏÎ½ bundles ===
print(f"âœ… Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬ {len(all_bundles)} bundles Î¼Îµ Ï€ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î· Ï„Î¹Î¼Î®:")
print(all_bundles.head(10))

# === 8. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÏ‰Î½ bundle Î¼Îµ Ï„Î¹Î¼Î­Ï‚ ===
all_bundles.to_csv("bundle_prices.csv", index=False)
print("âœ… Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ 'bundle_prices.csv' Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚ ÎºÎ±Î¹ Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï„Î¹Ï‚ Ï„ÎµÎ»Î¹ÎºÎ­Ï‚ Î´Ï…Î½Î±Î¼Î¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚ Î³Î¹Î± ÏŒÎ»Î± Ï„Î± bundles.")

# === ğŸ” Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Bundle vs Single Price Î³Î¹Î± Volume Bundles ===

# Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹, Ï…Ï€Î¿Î»ÏŒÎ³Î¹ÏƒÎµ SinglePrice (Ï„Î¹Î¼Î® 1 Ï„ÎµÎ¼Î±Ï‡Î¯Î¿Ï…)
if 'SinglePrice' not in volume_pricing.columns:
    volume_pricing['SinglePrice'] = volume_pricing['UnitPrice']

# Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹, Î´Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Suggested Bundle Title
if 'Suggested Bundle Title' not in volume_pricing.columns:
    volume_pricing['Suggested Bundle Title'] = volume_pricing['Qty'].astype(str) + 'x Product â€“ Offer Pack'

# Î Î¬ÏÎµ Î­Î½Î± Î´ÎµÎ¯Î³Î¼Î± 10 bundles Î³Î¹Î± Ï€Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ·
sample = volume_pricing.head(10).copy()

# === ğŸ“Š Bar Chart: Bundle vs Single Unit ===
import matplotlib.pyplot as plt

plt.figure(figsize=(25, 15))
bar_width = 0.35
x = range(len(sample))

# Î“ÎºÏÎ¹: 1 Ï„ÎµÎ¼Î¬Ï‡Î¹Î¿, Î ÏÎ¬ÏƒÎ¹Î½Î¿: Bundle
plt.bar(x, sample['SinglePrice'], width=bar_width, label='Single Unit Price', color='lightgray')
plt.bar([p + bar_width for p in x], sample['FinalPrice'], width=bar_width, label='Bundle Price', color='mediumseagreen')

plt.xticks([p + bar_width / 2 for p in x], sample['Suggested Bundle Title'], rotation=45, ha='right')
plt.ylabel("Price (â‚¬)")
plt.title("ğŸ“¦ Bundle vs Single Product Price (Sample)")
plt.legend()
plt.grid(axis='y')
plt.tight_layout()
plt.show()

print("ğŸ“‹ Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ ÏƒÏ„Î¿ orders_df:")
print(orders_df.columns.tolist())

from datetime import timedelta

# === 1. Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± ===
orders_df['CreatedDate'] = pd.to_datetime(orders_df['CreatedDate'], errors='coerce')

# Î¤ÎµÎ»ÎµÏ…Ï„Î±Î¯ÎµÏ‚ 30 Î·Î¼Î­ÏÎµÏ‚
last_30_days = orders_df[orders_df['CreatedDate'] >= (orders_df['CreatedDate'].max() - timedelta(days=30))]

# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î·Î¼ÎµÏÎ®ÏƒÎ¹Ï‰Î½ Ï€Ï‰Î»Î®ÏƒÎµÏ‰Î½ Î±Î½Î¬ SKU
daily_sales = last_30_days.groupby('SKU')['OrderQuantity'].sum() / 30

# Î›ÎµÎ¾Î¹ÎºÏŒ Î±Ï€Î¿Î¸Î­Î¼Î±Ï„Î¿Ï‚ Î±Î½Î¬ SKU
inventory_lookup = dict(zip(inventory_df['SKU'], inventory_df['Quantity']))

# === 2. Forecast Î³Î¹Î± Volume Bundles ===
volume_forecasts = []

for _, row in volume_pricing.iterrows():
    sku = row['SKU']  # Î’ÎµÎ²Î±Î¹ÏÏƒÎ¿Ï… ÏŒÏ„Î¹ Î· ÏƒÏ„Î®Î»Î· Î»Î­Î³ÎµÏ„Î±Î¹ Î­Ï„ÏƒÎ¹
    price = row['FinalPrice']

    # Î—Î¼ÎµÏÎ®ÏƒÎ¹Î¿Ï‚ ÏÏ…Î¸Î¼ÏŒÏ‚ Ï€ÏÎ»Î·ÏƒÎ·Ï‚
    daily_rate = daily_sales.get(sku, 1)

    # Î‘Ï€ÏŒÎ¸ÎµÎ¼Î±
    stock = inventory_lookup.get(sku, 0)

    # Î ÏŒÏƒÎµÏ‚ Î¼Î­ÏÎµÏ‚ Î¸Î± ÎºÏÎ±Ï„Î®ÏƒÎµÎ¹ Ï„Î¿ bundle
    duration = int(stock / daily_rate)

    # Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½ÎµÏ‚ Ï€Ï‰Î»Î®ÏƒÎµÎ¹Ï‚
    expected_sales = int(daily_rate * duration)

    # Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î¿ Î­ÏƒÎ¿Î´Î¿
    revenue = expected_sales * price

    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·
    volume_forecasts.append({
        'Bundle Title': row['Suggested Bundle Title'],
        'SKU': sku,
        'FinalPrice (â‚¬)': round(price, 2),
        'Duration (days)': duration,
        'Expected Sales': expected_sales,
        'Forecasted Revenue (â‚¬)': round(revenue, 2)
    })

# === 3. Î¤ÎµÎ»Î¹ÎºÏŒÏ‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚ ===
volume_forecast_df = pd.DataFrame(volume_forecasts)
volume_forecast_df = volume_forecast_df.sort_values(by='Forecasted Revenue (â‚¬)', ascending=False)

# Î ÏÎ¿Î²Î¿Î»Î®
volume_forecast_df.head(10)

# === 4. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Ï‰Î½ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ Î³Î¹Î± chatbot ===
volume_forecast_df.to_csv("volume_bundle_forecasts.csv", index=False)
print("âœ… Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ 'volume_bundle_forecasts.csv' Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï„Î¹Ï‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎµÎ¯Î½Î±Î¹ Î­Ï„Î¿Î¹Î¼Î¿ Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· ÏƒÏ„Î¿Î½ chatbot.")

import matplotlib.pyplot as plt

# Top 10 Volume Bundles by revenue
top_volume = volume_forecast_df.head(10)

plt.figure(figsize=(12, 6))
plt.barh(top_volume['Bundle Title'], top_volume['Forecasted Revenue (â‚¬)'], color='skyblue')
plt.xlabel('Forecasted Revenue (â‚¬)')
plt.title('ğŸ’° Top 10 Volume Bundles by Forecasted Revenue')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()



rule_forecasts = []

for _, row in rule_pricing.iterrows():
    sku_a = row['SKU_A']
    sku_b = row['SKU_B']
    price = row['FinalPrice']

    # Daily sales Î³Î¹Î± ÎºÎ¬Î¸Îµ SKU
    rate_a = daily_sales.get(sku_a, 1)
    rate_b = daily_sales.get(sku_b, 1)

    # Stock Î³Î¹Î± ÎºÎ¬Î¸Îµ SKU
    stock_a = inventory_lookup.get(sku_a, 0)
    stock_b = inventory_lookup.get(sku_b, 0)

    # Î”Î¹Î¬ÏÎºÎµÎ¹Î± (Ï€ÏŒÏƒÎµÏ‚ Î¼Î­ÏÎµÏ‚ Î±Î½Ï„Î­Ï‡ÎµÎ¹ Ï„Î¿ bundle)
    duration = int(min(stock_a / rate_a, stock_b / rate_b))

    # Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½ÎµÏ‚ Ï€Ï‰Î»Î®ÏƒÎµÎ¹Ï‚
    expected_sales = int(min(rate_a * duration, rate_b * duration))

    # ÎˆÏƒÎ¿Î´Î±
    revenue = expected_sales * price

    rule_forecasts.append({
        'Bundle Title': row['Suggested Bundle Title'],
        'SKU A': sku_a,
        'SKU B': sku_b,
        'FinalPrice (â‚¬)': round(price, 2),
        'Duration (days)': duration,
        'Expected Sales': expected_sales,
        'Forecasted Revenue (â‚¬)': round(revenue, 2)
    })

# Î¤ÎµÎ»Î¹ÎºÏŒÏ‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚
rule_forecast_df = pd.DataFrame(rule_forecasts)
rule_forecast_df = rule_forecast_df.sort_values(by='Forecasted Revenue (â‚¬)', ascending=False)

# Î ÏÎ¿Î²Î¿Î»Î®
rule_forecast_df.head(10)

# === Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ rule-based bundles ===
rule_forecast_df.to_csv("rule_bundle_forecasts.csv", index=False)
print("âœ… Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ 'rule_bundle_forecasts.csv' Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ Î¼Îµ Ï„Î¹Ï‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î³Î¹Î± rule-based bundles.")

import matplotlib.pyplot as plt

top_rule = rule_forecast_df.head(8)
labels = [f"{a} + {b}" for a, b in zip(top_rule['SKU A'], top_rule['SKU B'])]

plt.figure(figsize=(12, 6))
bars = plt.barh(labels, top_rule['Forecasted Revenue (â‚¬)'], color='mediumseagreen')
plt.xlabel('Forecasted Revenue (â‚¬)')
plt.title('ğŸ”— Rule-Based Bundles â€“ Forecasted Revenue per Bundle')
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()





# === Thematic Bundle Forecast ===

thematic_forecasts = []

for _, row in thematic_pricing.iterrows():
    titles = [row['Item title A'], row['Item title B']]

    # Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· Ï„Î¯Ï„Î»Ï‰Î½ ÏƒÎµ SKUs (Ï€Î±Î¯ÏÎ½ÎµÎ¹ ÏŒÎ»Î± Ï„Î± SKUs Î¼Îµ Î±Ï…Ï„ÏŒÎ½ Ï„Î¿Î½ Ï„Î¯Ï„Î»Î¿)
    skus = orders_df[orders_df['Item title'].isin(titles)]['SKU'].unique().tolist()

    # Î‘Î½ Î´ÎµÎ½ Î²ÏÎ¿ÏÎ¼Îµ 2 SKU, Ï„Î¿ Ï€ÏÎ¿ÏƒÏ€ÎµÏÎ½Î¬Î¼Îµ
    if not skus or len(skus) < 2:
        continue

    # Î Ï‰Î»Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î±Ï€ÏŒÎ¸ÎµÎ¼Î± Î³Î¹Î± ÎºÎ¬Î¸Îµ SKU
    rate_skus = [daily_sales.get(sku, 1) for sku in skus]
    stock_skus = [inventory_lookup.get(sku, 0) for sku in skus]

    # Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î· Î´Î¹Î¬ÏÎºÎµÎ¹Î± (Ï„Î¿ bottleneck Ï„Î¿Ï… bundle)
    duration = int(min([stock / rate for stock, rate in zip(stock_skus, rate_skus)]))
    expected_sales = int(min([rate * duration for rate in rate_skus]))
    revenue = row['FinalPrice'] * expected_sales

    thematic_forecasts.append({
        'Bundle Title': row['Suggested Bundle Title'],
        'FinalPrice (â‚¬)': round(row['FinalPrice'], 2),
        'Duration (days)': duration,
        'Expected Sales': expected_sales,
        'Forecasted Revenue (â‚¬)': round(revenue, 2)
    })

# Î¤ÎµÎ»Î¹ÎºÏŒÏ‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚
thematic_forecast_df = pd.DataFrame(thematic_forecasts)
thematic_forecast_df = thematic_forecast_df.sort_values(by='Forecasted Revenue (â‚¬)', ascending=False)

# Î ÏÎ¿Î²Î¿Î»Î®
print(f"âœ… Î¥Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎ±Î½ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î³Î¹Î± {len(thematic_forecast_df)} thematic bundles.")
thematic_forecast_df.head(10)

# === Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ thematic bundles ===
thematic_forecast_df.to_csv("thematic_bundle_forecasts.csv", index=False)
print("âœ… Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ 'thematic_bundle_forecasts.csv' Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ Î¼Îµ Ï„Î¹Ï‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î³Î¹Î± thematic bundles.")

import matplotlib.pyplot as plt

# Top 8 thematic bundles by revenue
top_thematic = thematic_forecast_df.head(8)

# Plot
plt.figure(figsize=(12, 8))
plt.barh(top_thematic['Bundle Title'], top_thematic['Forecasted Revenue (â‚¬)'], color='darkorange')
plt.xlabel('Forecasted Revenue (â‚¬)')
plt.title('ğŸ¨ Thematic Bundles â€“ Forecasted Revenue per Bundle')
plt.gca().invert_yaxis()  # Most profitable bundle on top
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

# === Clearance Bundle Forecast ===

clearance_forecasts = []

for _, row in clearance_pricing.iterrows():
    sku_a = row['SKU_A']
    sku_b = row['SKU_B']
    price = row['FinalPrice']

    # Î—Î¼ÎµÏÎ®ÏƒÎ¹ÎµÏ‚ Ï€Ï‰Î»Î®ÏƒÎµÎ¹Ï‚ (fallback ÏƒÎµ 1 ÎµÎ¬Î½ Î»ÎµÎ¯Ï€ÎµÎ¹)
    rate_a = daily_sales.get(sku_a, 1)
    rate_b = daily_sales.get(sku_b, 1)

    # Î‘Ï€ÏŒÎ¸ÎµÎ¼Î±
    stock_a = inventory_lookup.get(sku_a, 0)
    stock_b = inventory_lookup.get(sku_b, 0)

    # Î”Î¹Î¬ÏÎºÎµÎ¹Î± bundle (Î¼Î­Ï‡ÏÎ¹ Î½Î± Ï„ÎµÎ»ÎµÎ¹ÏÏƒÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î¿ Î±Ï€ÏŒ Ï„Î± Î´ÏÎ¿ SKUs)
    duration = int(min(stock_a / rate_a, stock_b / rate_b))

    # Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½ÎµÏ‚ Ï€Ï‰Î»Î®ÏƒÎµÎ¹Ï‚
    expected_sales = int(min(rate_a * duration, rate_b * duration))

    # Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î± Î­ÏƒÎ¿Î´Î±
    revenue = expected_sales * price

    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î¿ Ï„ÎµÎ»Î¹ÎºÏŒ dataframe
    clearance_forecasts.append({
        'Bundle Title': row['Suggested Bundle Title'],
        'SKU A': sku_a,
        'SKU B': sku_b,
        'FinalPrice (â‚¬)': round(price, 2),
        'Duration (days)': duration,
        'Expected Sales': expected_sales,
        'Forecasted Revenue (â‚¬)': round(revenue, 2)
    })

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„ÎµÎ»Î¹ÎºÎ¿Ï DataFrame
clearance_forecast_df = pd.DataFrame(clearance_forecasts)
clearance_forecast_df = clearance_forecast_df.sort_values(by='Forecasted Revenue (â‚¬)', ascending=False)

# Î ÏÎ¿Î²Î¿Î»Î®
print(f"âœ… Î¥Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎ±Î½ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î³Î¹Î± {len(clearance_forecast_df)} clearance bundles.")
clearance_forecast_df.head(10)

import matplotlib.pyplot as plt

# ğŸ”Ÿ Î Î¬ÏÎµ Ï„Î± top 10 bundles Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î± Ï€ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î± Î­ÏƒÎ¿Î´Î±
top_clearance = clearance_forecast_df.sort_values(by='Forecasted Revenue (â‚¬)', ascending=False).head(10)

# ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î´Î¹Î±Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚
plt.figure(figsize=(12, 6))
plt.bar(top_clearance['Bundle Title'], top_clearance['Forecasted Revenue (â‚¬)'])
plt.title("Top 10 Clearance Bundles by Forecasted Revenue (â‚¬)")
plt.xlabel("Bundle Title")
plt.ylabel("Forecasted Revenue (â‚¬)")
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()


import pandas as pd

bundle_prices = pd.read_csv("bundle_prices.csv")
volume_forecast_df = pd.read_csv("volume_bundle_forecasts.csv")

print("âœ… Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± bundle_prices ÎºÎ±Î¹ volume_forecast_df")





print("ğŸ“¦ bundle_prices columns:")
print(bundle_prices.columns.tolist())

print("\nğŸ“ˆ volume_forecast_df columns:")
print(volume_forecast_df.columns.tolist())



# === ğŸ“Œ TEST CASE: ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Bundles Î¼Îµ >15% AOV ===

# Î¥Ï€Î¿Î¸ÎµÏ„Î¹ÎºÏŒ baseline AOV
current_aov = 20
target_aov = current_aov * 1.15

# Merge (Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î¿ ÏƒÏ„Î¹Ï‚ ÏƒÏ‰ÏƒÏ„Î­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Î±Î½ Ï‡ÏÎµÎ¹Î±ÏƒÏ„ÎµÎ¯)
merged_df = pd.merge(
    bundle_prices,
    volume_forecast_df,
    left_on='Suggested Bundle Title',
    right_on='Bundle Title'
)

merged_df['AvgPricePerItem'] = merged_df['FinalPrice'] / 3
aov_bundles = merged_df[
    (merged_df['Duration (days)'] <= 14) &
    (merged_df['AvgPricePerItem'] >= target_aov)
]

# === âœ… Î¤ÎµÏƒÏ„: Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 3 bundles Ï€Î¿Ï… Ï€Î»Î·ÏÎ¿ÏÎ½ Ï„Î¿ ÎºÏÎ¹Ï„Î®ÏÎ¹Î¿; ===
assert len(aov_bundles) >= 3, "âŒ Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÏÎºÎµÏ„Î¬ bundles Ï€Î¿Ï… Î±Ï…Î¾Î¬Î½Î¿Ï…Î½ AOV ÎºÎ±Ï„Î¬ 15%!"

print(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(aov_bundles)} bundles Î¼Îµ Î±ÏÎ¾Î·ÏƒÎ· AOV â‰¥ 15% Î¼Î­ÏƒÎ± ÏƒÎµ 14 Î·Î¼Î­ÏÎµÏ‚.")

# === ğŸ“Š Plot: Top 5 AOV-Boosting Bundles ===
import matplotlib.pyplot as plt

top_plot = aov_bundles.sort_values(by='Forecasted Revenue (â‚¬)', ascending=False).head(5)

plt.figure(figsize=(12, 6))
plt.bar(top_plot['Suggested Bundle Title'], top_plot['Forecasted Revenue (â‚¬)'])
plt.title("Top 5 Bundles with >15% AOV Boost (Next 2 Weeks)")
plt.ylabel("Forecasted Revenue (â‚¬)")
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()


import joblib

# === NLP Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€ÏÏŒÎ¸ÎµÏƒÎ·Ï‚ ===
vectorizer = joblib.load("intent_vectorizer.joblib")
clf = joblib.load("intent_classifier.joblib")


# === Î¤Î¿ Î¼Î¿Î½Î±Î´Î¹ÎºÏŒ endpoint Ï€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏƒÎ±Î¹ ===
@app.route("/api/bundles")
def get_bundles():
    sample = all_bundles.sample(n=6, random_state=random.randint(1, 99999))
    print("ğŸ“¤ Bundles sent to frontend:")
    print(sample[['Suggested Bundle Title', 'FinalPrice', 'BundleType']])
    print("â¡ï¸ Sending bundles:", sample.head(2).to_dict(orient="records"))
    return jsonify(sample.to_dict(orient="records"))

@app.route("/api/allBundles")
def get_all_bundles():
    print(f"ğŸ“¤ Sending ALL {len(all_bundles)} bundles to frontend...")
    return jsonify(all_bundles.to_dict(orient="records"))

from flask import Flask, jsonify, request
from flask_cors import CORS
import pandas as pd
import os
import joblib

app = Flask(__name__)
CORS(app)

# === NLP Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€ÏÏŒÎ¸ÎµÏƒÎ·Ï‚ ===
vectorizer = joblib.load("intent_vectorizer.joblib")
clf = joblib.load("intent_classifier.joblib")

# === Helper Î³Î¹Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ· CSV ===
def load_csv(name):
    return pd.read_csv(os.path.join(os.path.dirname(__file__), name))

@app.route("/api/advisor-data")
def advisor_data():
    from flask import request, jsonify
    import os
    import pandas as pd

    question = request.args.get("question", "").lower().strip()

    # === NLP Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Ï€ÏÏŒÎ¸ÎµÏƒÎ·Ï‚ ===
    X_q = vectorizer.transform([question])
    predicted_intent = clf.predict(X_q)[0]

    # === Keyword overrides ===
    if any(x in question for x in ["forecast", "revenue", "Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·", "Î­ÏƒÎ¿Î´Î¿"]):
        predicted_intent = "forecast"
    elif any(x in question for x in ["volume", "multipack", "Ï€Î¿ÏƒÏŒÏ„Î·Ï„Î±"]):
        predicted_intent = "volume"
    elif any(x in question for x in ["clear", "Î±Ï€ÏŒÎ¸ÎµÎ¼Î±", "stock", "Î¾ÎµÏ€Î¿ÏÎ»Î·Î¼Î±"]):
        predicted_intent = "clearance"
    elif any(x in question for x in ["theme", "summer", "Î´ÏÏÎ¿", "gift", "season"]):
        predicted_intent = "thematic"
    elif any(x in question for x in ["price", "Ï„Î¹Î¼Î®", "margin", "discount"]):
        predicted_intent = "price"
    elif any(x in question for x in ["brand", "top seller", "ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±"]):
        predicted_intent = "rule"
    elif any(x in question for x in ["aov", "order value", "ÎºÎ±Î»Î¬Î¸Î¹"]):
        predicted_intent = "aov"

    # === Î¦ÏŒÏÏ„Ï‰ÏƒÎ· CSVs ===
    def load_csv(name):
        return pd.read_csv(os.path.join(os.path.dirname(__file__), name))

    inventory = load_csv("data/inventory.csv")
    bundle_prices = load_csv("bundle_prices.csv")
    volume_forecasts = load_csv("volume_bundle_forecasts.csv")
    volume_bundles = load_csv("volume_bundles.csv")
    thematic_bundles = load_csv("thematic_bundles.csv")
    thematic_forecasts = load_csv("thematic_bundle_forecasts.csv")
    rule_forecasts = load_csv("rule_bundle_forecasts.csv")
    top_seller = load_csv("top_seller_bundles.csv")
    clearance = load_csv("clearance_bundles.csv")

    context = f"\nğŸ’¡ Intent Detected: {predicted_intent}\n"

    # === Î•Ï€Î¹Î»Î¿Î³Î® Î²Î¬ÏƒÎµÎ¹ intent ===
    if predicted_intent == "aov":
        sample = volume_forecasts.sort_values("Forecasted Revenue (â‚¬)", ascending=False).sample(5)
        context += "\nğŸ“Š High-AOV Candidates (Sample):\n"
        context += sample[['Bundle Title', 'FinalPrice (â‚¬)', 'Forecasted Revenue (â‚¬)']].to_string(index=False)

    elif predicted_intent == "price":
        sample = bundle_prices.sort_values("FinalPrice", ascending=False).sample(5)
        context += "\nğŸ’° Price-Focused Bundles (Sample):\n"
        context += sample[['Suggested Bundle Title', 'FullPrice', 'FinalPrice', 'DiscountRate']].to_string(index=False)

    elif predicted_intent == "volume":
        sample = volume_bundles.sample(5)
        context += "\nğŸ“¦ Volume-Based Bundles:\n"
        context += sample[['Suggested Bundle Title', 'Qty', 'Item title']].to_string(index=False)

    elif predicted_intent == "forecast":
        forecast_df = pd.concat([
            volume_forecasts[['Bundle Title', 'Forecasted Revenue (â‚¬)']],
            thematic_forecasts[['Bundle Title', 'Forecasted Revenue (â‚¬)']],
            rule_forecasts[['Bundle Title', 'Forecasted Revenue (â‚¬)']]
        ])
        sample = forecast_df.sort_values("Forecasted Revenue (â‚¬)", ascending=False).sample(6)
        context += "\nğŸ“ˆ Forecasted Revenue â€“ Sample:\n"
        context += sample.to_string(index=False)

    elif predicted_intent == "clearance":
        sample = clearance.sample(min(5, len(clearance)))
        context += "\nğŸš¨ Clearance Bundles:\n"
        context += sample[['Top Seller Title', 'Clearance Title', 'Brand']].to_string(index=False)

    elif predicted_intent == "thematic":
        sample = thematic_bundles.sample(5)
        context += "\nğŸ¨ Thematic Bundles:\n"
        context += sample[['Item title A', 'Item title B', 'Suggested Bundle Title']].to_string(index=False)

    elif predicted_intent == "rule":
        sample = top_seller.sample(5)
        context += "\nğŸ“ˆ Top-Seller Brand Bundles:\n"
        context += sample[['Primary Title', 'Bundled With Title', 'Brand']].to_string(index=False)

    else:
        sample = bundle_prices.sample(5)
        context += "\nğŸ” No exact match â€“ here are random bundle suggestions:\n"
        context += sample[['Suggested Bundle Title', 'FinalPrice', 'BundleType']].to_string(index=False)

    print("ğŸ§  Predicted intent:", predicted_intent)
    print("ğŸ‘‰ Full question:", question)

    return jsonify({"context": context})


if __name__ == "__main__":
    app.run(debug=True, use_reloader=False)